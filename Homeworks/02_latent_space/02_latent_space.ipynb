{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "As already discussed in class, autoencoders may be used to reduce a feature vector in the so-called **latent space**. The size for this space varies depending on the problem and the desired reduction in dimensionallity. For small datasets and under specific circumstances, we could use a 2D or 3D latent space, with the advantage of being able to see what such space looks like. That is the goal for this homework. We will generate an array with a one-hot encoding for all 118 elements in the periodic table, then, by means of training an autoencoder using a 2D latent space, we will plot the resulting reduced information and see how a neural network encodes the information for all the elements. Moreover, we will compare whether the use of different activation functions leads to different encoding behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "### Define the number of elements\n",
    "#\n",
    "elements_in_periodic_table = 118\n",
    "#\n",
    "### Generate the one-hot encoding for all elements\n",
    "#\n",
    "one_hot_elements_in_periodic_table = torch.eye(elements_in_periodic_table, dtype=torch.float)\n",
    "#\n",
    "### Plot the one-hot array\n",
    "#\n",
    "plt.figure( figsize=(8,8) )\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.imshow(one_hot_elements_in_periodic_table, cmap='gray', aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element in `one_hot_elements_in_periodic_table` has been assigned its own column, and a 1 or 0 is used to indicate whether the element is present or not, respectively. This is the training data. All of it. You do not need to divide it into training and testing.\n",
    "\n",
    "## Your tasks\n",
    "\n",
    "In order to compare the effects of the activation function (if any), **you will train three neural networks**. All with the same architecture but choosing a different activation function for each network. The following list includes six suggestions. Pick three.\n",
    "\n",
    "* [LogSigmoid](https://pytorch.org/docs/stable/generated/torch.nn.LogSigmoid.html#torch.nn.LogSigmoid)\n",
    "* [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU)\n",
    "* [Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid)\n",
    "* [SiLU](https://pytorch.org/docs/stable/generated/torch.nn.SiLU.html#torch.nn.SiLU)\n",
    "* [Tanh](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html#torch.nn.Tanh)\n",
    "* [Tanhshrink](https://pytorch.org/docs/stable/generated/torch.nn.Tanhshrink.html#torch.nn.Tanhshrink)\n",
    "\n",
    "On the other hand, a 2D latent space is sufficient for comparison. This choice makes plotting simpler. But feel free to use a 3D or larger dimensionallity, keeping in mind that you will need to plot such hyper space.\n",
    "\n",
    "> ### Assignment\n",
    ">\n",
    "> Plot the resulting latent space for your three autoencoders and dicuss your findings.\n",
    "\n",
    "## Considerations\n",
    "\n",
    "- Use matplotlib to show and compare your three latent spaces.\n",
    "- Please implement your three neural networks in this notebook instead of using an external .py file.\n",
    "- Remember that you must optimize the learning rate, weight decay, and number of epochs for each of your networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your implementation\n",
    "\n",
    "> **You will earn extra credits for the organization, implementation, and legibility of your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
