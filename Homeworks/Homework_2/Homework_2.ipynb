{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac7043f",
   "metadata": {},
   "source": [
    "# Homework 2: Learning Chemical Structure with Autoencoders\n",
    "\n",
    "In this notebook, you'll explore how an autoencoder can learn a compact representation of chemical elements based on their physical and chemical properties.\n",
    "\n",
    "You will:\n",
    "- Load a dataset of periodic elements containing data from Hydrogen (H) up to Radon (Rn),\n",
    "- Normalize the data and encode categorical features,\n",
    "- Train an autoencoder to compress features into 2D,\n",
    "- Visualize the learned latent space,\n",
    "- Interpret how chemical structure is captured in the latent space.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Œ Dataset Features\n",
    "\n",
    "- `atomic_mass`\n",
    "- `electronegativity`\n",
    "- `type` (metal, nonmetal, metalloid)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Your Tasks\n",
    "\n",
    "1. Preprocess the dataset (handle NaNs, normalize, encode types).\n",
    "2. Define and train an autoencoder with 2D latent space.\n",
    "3. Plot and interpret the latent space. Utilize color, shape, and size to visualize the data in the latent space.\n",
    "4. Optimize the Hyperparameters.\n",
    "5. Interprete the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd395d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"periodic_table_properties.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55dbad2",
   "metadata": {},
   "source": [
    "## 1. Preprocess the dataset\n",
    "\n",
    "- Check the dataset for **missing or NaN** entries. What entries are missing for which elements? What would be a reasonable replacement value? Perform the replacement.\n",
    "- Normalize numerical values.\n",
    "- Encode types the element labels using a one hot encoding. Encode the type using a type encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63dd1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing electronegativity values\n",
    "\n",
    "\n",
    "# Encode metal type\n",
    "\n",
    "\n",
    "# Normalize numerical values\n",
    "\n",
    "\n",
    "# Combine features\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Feature matrix shape: {X_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86781c12",
   "metadata": {},
   "source": [
    "## 2. Define the Autoencoder and Optimize the Weights\n",
    "\n",
    "Create an autoencoder that has a 2D latent space. To optimize the autoencoders architecture, you should investigate how increasing the number of hidden layers affects your performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1bd343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=2):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "          ...\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "          ...\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f04713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the autoencoder\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = Autoencoder(input_dim=X_tensor.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x_recon, _ = model(X_tensor)\n",
    "    loss = criterion(x_recon, X_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f91488",
   "metadata": {},
   "source": [
    "## 3. Latent space\n",
    "\n",
    "- Visualize the learned latent space.\n",
    "- To help identify the structure of the latent space I recommend using color, size, and symbol shapes.\n",
    "- Color each element entry by its electronegativity, use different symbols for the three different types, and different size based on the atomic mass. Label each point by its element symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0711ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    _, Z = model(X_tensor)\n",
    "Z_np = Z.numpy()\n",
    "\n",
    "# Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d0eba6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f514a634",
   "metadata": {},
   "source": [
    "## 4. Optimize the Hyperparameters\n",
    "\n",
    "- Using cross-valdiation, optimize the learning rate, choice of activation function (up to three, e.g., Tanh, ReLU), number of epochs, and number of hidden layers (up to two)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb2a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization using cross-validation\n",
    "\n",
    "# Define the parameter grid\n",
    "\n",
    "\n",
    "# Create a function to train and evaluate the model\n",
    "\n",
    "\n",
    "# Perform grid search\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Best parameters: {best_params}, Best loss: {best_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cf52f6",
   "metadata": {},
   "source": [
    "## ðŸ§  5. Interpretation\n",
    "\n",
    "- What do you notice about the placement of metals, nonmetals, and metalloids?\n",
    "- Are chemically similar elements grouped together?\n",
    "- What might each latent dimension represent?\n",
    "- How does the activation functions affect compression?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
