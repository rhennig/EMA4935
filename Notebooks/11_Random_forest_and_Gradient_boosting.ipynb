{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest and gradient boosting trees\n",
    "\n",
    "Put simple, a **random forest** is an ensemble of decision trees in which each decision tree is trained with a specific random noise. The logic behind this model is that multiple uncorrelated indivdual decision trees mixed randomly are expected to perform better as a group than they do alone.\n",
    "\n",
    "The main idea behind **gradient boosting** is building models sequentially, where each subsequent model try to reduce the error from the previous one based on a *loss function*. Therefore, the goal is to minimize the loss function by addition of weak learners using gradient descent.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook we will continue elaborating on decision trees. Here we will illustrate the use of Random Forest and Gradient Boosting for classification and regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy      as np\n",
    "import pandas     as pd\n",
    "\n",
    "# pip installation of mendeleev is not up to date, so we need to install it from the git repository\n",
    "# ! pip install git+https://github.com/lmmentel/mendeleev.git\n",
    "import mendeleev  as mendel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn                 import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble        import RandomForestRegressor\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.ensemble        import GradientBoostingRegressor\n",
    "from sklearn.ensemble        import GradientBoostingClassifier\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.metrics         import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pymatgen.core.periodic_table import Element\n",
    "\n",
    "plt.rc('xtick', labelsize=18)\n",
    "plt.rc('ytick', labelsize=18)\n",
    "\n",
    "blue   = '#0021A5'\n",
    "orange = '#FA4616'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data for classification\n",
    "\n",
    "We will select 47 elements that occur in the fcc, hcp, and bcc structure. The elements listed were chosen because querying them for these properties yields a dataset with no unknown values, and because they represent the three most common crystallographic structures. We then query both Pymatgen and Mendeleev to get a complete set of properties per element. We will use this data to create the features from which the model will train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the attributes that we will query from the Mendeleev and Pymatgen databases\n",
    "\n",
    "fcc = ['Ag', 'Al', 'Au', 'Cu', 'Ir',\n",
    "       'Ni', 'Pb', 'Pd', 'Pt', 'Rh',\n",
    "       'Th', 'Yb']\n",
    "\n",
    "bcc = ['Ba', 'Ca', 'Cr', 'Cs', 'Eu',\n",
    "       'Fe', 'Li', 'Mn', 'Mo', 'Na',\n",
    "       'Nb', 'Rb', 'Ta', 'V',  'W']\n",
    "\n",
    "hcp = ['Be', 'Cd', 'Co', 'Dy', 'Er',\n",
    "       'Gd', 'Hf', 'Ho', 'Lu', 'Mg',\n",
    "       'Re', 'Ru', 'Sc', 'Tb', 'Ti',\n",
    "       'Tl', 'Tm', 'Y',  'Zn', 'Zr']\n",
    "\n",
    "query_mendeleev = ['atomic_number', 'atomic_volume',\n",
    "                   'boiling_point', 'en_ghosh', \n",
    "                   'evaporation_heat', 'heat_of_formation',\n",
    "                   'melting_point', 'specific_heat']\n",
    "\n",
    "query_pymatgen  = ['atomic_mass', 'atomic_radius',\n",
    "                   'electrical_resistivity', 'molar_volume',\n",
    "                   'bulk_modulus', 'youngs_modulus',\n",
    "                   'average_ionic_radius', 'density_of_solid',\n",
    "                   'coefficient_of_linear_thermal_expansion']\n",
    "\n",
    "elements = fcc + bcc + hcp\n",
    "\n",
    "queries  = query_mendeleev + query_pymatgen\n",
    "\n",
    "# randomly shuflle the elements\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(elements)\n",
    "\n",
    "all_attributes, all_labels = [], []\n",
    "\n",
    "# Iterate over elements\n",
    "for item in elements:\n",
    "    attributes = []\n",
    "    \n",
    "    element = mendel.element(item)\n",
    "\n",
    "    # Query Mendeleev\n",
    "    for i in query_mendeleev:    \n",
    "        attributes.append( getattr(element,i) )\n",
    "\n",
    "    element = Element(item)\n",
    "\n",
    "    # Query Pymatgen\n",
    "    for i in query_pymatgen:\n",
    "        attributes.append( getattr(element,i) )\n",
    "    \n",
    "    # Append queries to the list\n",
    "    all_attributes.append(attributes)\n",
    "    \n",
    "    if (item in fcc):\n",
    "        all_labels.append(0)\n",
    "\n",
    "    elif (item in bcc):\n",
    "        all_labels.append(1)\n",
    "\n",
    "    elif (item in hcp):\n",
    "        all_labels.append(2)\n",
    "\n",
    "# Create a dataframe with the values\n",
    "dataframe = pd.DataFrame(all_attributes, columns=queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the values are not available for a reduced number of elements, so we will fill manually that information to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value for Cesium\n",
    "# Ref: David R. Lide (ed), CRC Handbook of Chemistry and Physics, 84th Edition. CRC Press. Boca Raton, Florida, 2003\n",
    "\n",
    "idx = dataframe.index[dataframe['atomic_number'] == 55]\n",
    "jdx = dataframe.columns.get_loc(\"coefficient_of_linear_thermal_expansion\")\n",
    "\n",
    "dataframe.iloc[idx, jdx] = 0.000097 \n",
    "\n",
    "# Missing value for Rubidium\n",
    "# Ref: https://www.azom.com/article.aspx?ArticleID=1834\n",
    "\n",
    "idx = dataframe.index[dataframe['atomic_number'] == 37]\n",
    "jdx = dataframe.columns.get_loc(\"coefficient_of_linear_thermal_expansion\")\n",
    "\n",
    "dataframe.iloc[idx, jdx] = 0.000090 \n",
    "\n",
    "# Missing value for Ruthenium\n",
    "# Ref: https://www.webelements.com/ruthenium/thermochemistry.html\n",
    "\n",
    "idx = dataframe.index[dataframe['atomic_number'] == 44]\n",
    "jdx = dataframe.columns.get_loc(\"evaporation_heat\")\n",
    "\n",
    "dataframe.iloc[idx, jdx] = 595 # kJ/mol \n",
    "\n",
    "\n",
    "# Missing value for Zirconium\n",
    "# Ref: https://materialsproject.org/materials/mp-131\n",
    "\n",
    "idx = dataframe.index[dataframe['atomic_number'] == 40]\n",
    "jdx = dataframe.columns.get_loc(\"bulk_modulus\")\n",
    "\n",
    "dataframe.iloc[idx, jdx] = 94 # GPa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Preprocessing the data\n",
    "\n",
    "- We normalize the data and randomly split it into training and testing sets.\n",
    "\n",
    "- We have 47 elements for which the crystal structure is known and we will use 40 of these as a training set and the remaining 7 as testing set.\n",
    "\n",
    "- We will again use the Standard Score Normalization, which subtracts the mean of the feature and divide by its standard deviation.\n",
    "$$\n",
    "\\overline{X} = \\frac{X - µ}{σ}\n",
    "$$\n",
    "While our model might converge without feature normalization, the resultant model would be difficult to train and would be dependent on the choice of units used in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attributes = [ list(dataframe.iloc[x]) for x in range( len(all_attributes) ) ]\n",
    "\n",
    "all_attributes = np.array(all_attributes, dtype = float)\n",
    "all_labels     = np.array(all_labels,     dtype = int)\n",
    "\n",
    "# Split data into 87% training and 13% testing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_attributes, all_labels, test_size=0.13, random_state=42)\n",
    "\n",
    "# Normalize the data\n",
    "\n",
    "mean = np.mean(all_attributes, axis = 0)\n",
    "std  = np.std(all_attributes,  axis = 0)\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_test  = (X_test  - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest Classification\n",
    "\n",
    "The fundamental idea behind a random forest is to combine many decision trees into a single model. Each decision tree in the forest considers a random subset of features and only has access to a random set of the training data points. This increases diversity in the forest leading to more robust overall predictions. When doing a classification, where the targets are a discrete class label, the random forest algorithm takes the majority vote for the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object\n",
    "random_forest_classification = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we created the object we have to optimize the hyperparameters for the model. Let's create a list with the available choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the hyperparameters that can be tuned\n",
    "for idx, key in enumerate( random_forest_classification.get_params().keys() ):\n",
    "    print(f'({idx+1:2d}): {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Assignment\n",
    ">\n",
    "> Optimize `min_samples_split`, `max_depth`, and `min_samples_leaf`. Then set the classification object with those parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we determined the optimal hyperparameters, we can train the model and evaluate its performance. The following code trains the model and evaluates its performance using the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "random_forest_classification.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for training and testing dataset\n",
    "predicted_train = random_forest_classification.predict(X_train)\n",
    "predicted_test  = random_forest_classification.predict(X_test)\n",
    "\n",
    "# Model Accuracy for training and testing set, how often is the classifier correct?\n",
    "print(f'Training accuracy = '\n",
    "      f'{accuracy_score(y_train, predicted_train):.3f}')\n",
    "\n",
    "print(f'Testing accuracy  = '\n",
    "      f'{accuracy_score(y_test, predicted_test):.3f}')\n",
    "\n",
    "# Plot the tree\n",
    "label_names = ('fcc', 'bcc', 'hcp')\n",
    "\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "\n",
    "# Select an individual decision tree, here 0.\n",
    "_ = tree.plot_tree(random_forest_classification.estimators_[0], feature_names=queries,\n",
    "                   class_names = label_names, filled=True, impurity=True, rounded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of comparison, we can create a dataframe and collect the labels predicted by our model and the actual labels. We can then compare the two and see how well our model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = np.hstack((y_train, y_test), dtype=str)\n",
    "predicted = np.hstack((predicted_train, predicted_test), dtype=str)\n",
    "\n",
    "for i, j in zip( ['0', '1', '2'], ['fcc', 'bcc', 'hcp'] ):\n",
    "    reference[reference==i] = j\n",
    "    predicted[predicted==i] = j\n",
    "\n",
    "data_dictionary = {'AtomicNumber': dataframe['atomic_number'].values,\n",
    "                   'Reference': reference,\n",
    "                   'Predicted': predicted,\n",
    "                   'Status': np.where(reference == predicted, 'Correct', 'Incorrect')}\n",
    "\n",
    "reference_vs_predicted = pd.DataFrame(data_dictionary)\n",
    "\n",
    "reference_vs_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient Boosting Classification\n",
    "\n",
    "We can alternatively use gradient boosting an compare with the preocious method. We will use the same training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "gradient_boosting_classification = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before optimizing the hyperparameters, let's list the hyperparameters that can be tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, key in enumerate( gradient_boosting_classification.get_params().keys() ):\n",
    "    print(f'({idx+1:2d}): {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Assignment\n",
    ">\n",
    "> Optimize `min_samples_split`, `max_depth`, `min_samples_leaf`, and `learning_rate`. Then set the classification object with those parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we optimized the hyperparameters, we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree Classifer\n",
    "gradient_boosting_classification.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for training and testing dataset\n",
    "predicted_train = gradient_boosting_classification.predict(X_train)\n",
    "predicted_test  = gradient_boosting_classification.predict(X_test)\n",
    "\n",
    "# Model Accuracy for training and testing set, how often is the classifier correct?\n",
    "print(f'Training accuracy = '\n",
    "      f'{accuracy_score(y_train, predicted_train):.3f}')\n",
    "\n",
    "print(f'Testing accuracy  = '\n",
    "      f'{accuracy_score(y_test, predicted_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reference function that generates our data\n",
    "def reference_function(x):\n",
    "    return np.cos(x) + 2.0*np.sin(x) + 3.0*np.cos(2.0*x)\n",
    "\n",
    "np.random.seed(seed=5)\n",
    "\n",
    "# Generate a data set for machine learning\n",
    "x = np.linspace(0, 2, 300)\n",
    "x = x + np.random.normal(0.0, 0.3, x.shape)\n",
    "\n",
    "y = reference_function(x) + np.random.normal(0.0,1.0, x.shape)\n",
    "\n",
    "# Split the dataset into 80% for training and 20% for testing\n",
    "x = x.reshape( (-1,1) )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=21)\n",
    "\n",
    "# Plot the training and testing dataset\n",
    "fig,ax=plt.subplots( figsize=(8,8) )\n",
    "\n",
    "ax.scatter(X_train, y_train, c=blue, label='Training')\n",
    "ax.scatter(X_test, y_test,   c=orange, label='Testing')\n",
    "\n",
    "ax.set_title('Training and testing data',fontsize=20)\n",
    "\n",
    "ax.set_xlabel('X Values',fontsize=18)\n",
    "ax.set_ylabel(r'$ \\cos(x)+2\\sin(x)+3\\cos(2x)$',fontsize=18)\n",
    "\n",
    "plt.legend(loc='best', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Forest Regression\n",
    "\n",
    "Contrary to the classification task, the prediction of a continuous variable is computed for the average of all the individual decision tree estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object\n",
    "random_forest_regression = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, we will optimize the hyperparameters of the random forest regression model using a grid search. Let's list our choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the hyperparameters that can be tuned\n",
    "for idx, key in enumerate( random_forest_regression.get_params().keys() ):\n",
    "    print(f'({idx+1:2d}): {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Assignment\n",
    ">\n",
    "> Optimize `min_impurity_decrease`, `min_samples_split`, `max_depth`, `min_samples_leaf`, and `max_leaf_nodes`. Then set the regression object with those parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train our model and evaluate its performance using the RMSE metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranin the optimized regression model\n",
    "random_forest_regression.fit(X_train, y_train)\n",
    "\n",
    "# Ccoefficient of determination for the prediction\n",
    "print(f'Training score = '\n",
    "      f'{random_forest_regression.score(X_train,y_train):.3f}')\n",
    "\n",
    "print(f'Testing  score = '\n",
    "      f'{random_forest_regression.score(X_test,y_test):.3f}\\n')\n",
    "\n",
    "predicted_train = random_forest_regression.predict(X_train)\n",
    "predicted_test = random_forest_regression.predict(X_test)\n",
    "\n",
    "training_rmse = np.sqrt( mean_squared_error(y_train, predicted_train) )\n",
    "testing_rmse = np.sqrt( mean_squared_error(y_test, predicted_test) )\n",
    "    \n",
    "print(f'Training RMSE = {training_rmse:.3f}')\n",
    "print(f'Testing  RMSE = {testing_rmse:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a series of sampling points to plot the model\n",
    "points  = 1000\n",
    "\n",
    "X_model = np.linspace(np.min(x), np.max(x), num=points)\n",
    "X_model = X_model.reshape( (-1,1) )\n",
    "\n",
    "y_model_predictions = random_forest_regression.predict(X_model)\n",
    "y_model_reference   = reference_function(X_model)\n",
    "\n",
    "# Plot the dataset\n",
    "fig,ax=plt.subplots( figsize=(16,8) )\n",
    "\n",
    "ax.scatter(X_train, y_train, c=blue, label='Data')\n",
    "ax.scatter(X_test, y_test, c=orange, label='Testing')\n",
    "\n",
    "ax.plot(X_model, y_model_predictions, c=blue, lw=2, label='Model')\n",
    "ax.plot(X_model, y_model_reference,   c='k', lw=4, label='Reference')\n",
    "\n",
    "ax.set_title('Performance', fontsize=20)\n",
    "\n",
    "ax.set_xlabel('x values', fontsize=18)\n",
    "ax.set_ylabel('y values', fontsize=18)\n",
    "\n",
    "ax.legend(loc='best', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots( figsize=(8,8) )\n",
    "\n",
    "ax.scatter(y_test, predicted_test, c=orange, label='Testing')\n",
    "ax.scatter(y_train, predicted_train, c=blue, label='Training')\n",
    "\n",
    "ax.set_xlabel('Reference', fontsize=18)\n",
    "ax.set_ylabel('Prediction', fontsize=18)\n",
    "\n",
    "ax.legend(loc='best', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object\n",
    "gradient_boosting_regression = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we must optimize the hyperparameters. But first, list our different choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the hyperparameters that can be tuned\n",
    "for idx, key in enumerate( gradient_boosting_regression.get_params().keys() ):\n",
    "    print(f'({idx+1:2d}): {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `learning_rate` parameter controls the step size at which the model updates the predictions at each boosting stage. It scales the contribution of each new tree, effectively determining how much influence each tree has on the final prediction.\n",
    "\n",
    "Default value: 0.1\n",
    "\n",
    "Effect:\n",
    "  - Lower values (e.g., 0.01): Slower learning, requires more trees to achieve the same performance, but improves generalization.\n",
    "  - Higher values (e.g., 0.5 or 1.0): Faster learning, but can lead to overfitting if too large.\n",
    "\n",
    "The `n_estimators` parameter defines the number of boosting stages (trees) to be used in the ensemble. Each tree corrects the residuals of the previous ones to improve prediction accuracy.\n",
    "\n",
    "Default value: 100\n",
    "\n",
    "Effect:\n",
    "  - Higher values (e.g., 500, 1000): Improve performance but increase training time and risk overfitting (if not regularized).\n",
    "  - Lower values (e.g., 50, 100): Faster training but may lead to underfitting.\n",
    "\n",
    "Trade-off between `learning_rate` and `n_estimators:`\n",
    "  - A smaller learning_rate (e.g., 0.01) often requires a larger n_estimators (e.g., 500 or more).\n",
    "  - A larger learning_rate (e.g., 0.1 or 0.2) can work well with a smaller n_estimators (e.g., 100 to 200).\n",
    "  - Typically, lower learning rates (e.g., 0.01 to 0.1) combined with more trees (n_estimators) lead to better generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Assignment\n",
    ">\n",
    "> Optimize `learning_rate` and `n_estimators`. Then set the regression object with those parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we proceed to train our model with the optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranin the optimized regression model\n",
    "gradient_boosting_regression.fit(X_train, y_train)\n",
    "\n",
    "# Ccoefficient of determination for the prediction\n",
    "print(f'Training score = {gradient_boosting_regression.score(X_train,y_train):.3f}')\n",
    "print(f'Testing  score = {gradient_boosting_regression.score(X_test,y_test):.3f}\\n')\n",
    "\n",
    "predicted_train = gradient_boosting_regression.predict(X_train)\n",
    "predicted_test = gradient_boosting_regression.predict(X_test)\n",
    "\n",
    "training_rmse = np.sqrt( mean_squared_error(y_train, predicted_train) )\n",
    "testing_rmse = np.sqrt( mean_squared_error(y_test, predicted_test) )\n",
    "    \n",
    "print(f'Training RMSE = {training_rmse:.3f}')\n",
    "print(f'Testing  RMSE = {testing_rmse:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot our model to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a series of sampling points to plot the model\n",
    "points  = 1000\n",
    "\n",
    "X_model = np.linspace(np.min(x), np.max(x), num=points)\n",
    "X_model = X_model.reshape( (-1,1) )\n",
    "\n",
    "y_model_predictions = gradient_boosting_regression.predict(X_model)\n",
    "y_model_reference   = reference_function(X_model)\n",
    "\n",
    "# Plot the dataset\n",
    "fig,ax=plt.subplots( figsize=(16,8) )\n",
    "\n",
    "ax.scatter(X_train, y_train, c=blue, label='Data')\n",
    "ax.scatter(X_test, y_test, c=orange, label='Testing')\n",
    "\n",
    "ax.plot(X_model, y_model_predictions, c=blue, lw=2, label='Model')\n",
    "ax.plot(X_model, y_model_reference,   c='k', lw=4, label='Reference')\n",
    "\n",
    "ax.set_title('Performance', fontsize=20)\n",
    "\n",
    "ax.set_xlabel('x values', fontsize=18)\n",
    "ax.set_ylabel('y values', fontsize=18)\n",
    "\n",
    "ax.legend(loc='best', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots( figsize=(8,8) )\n",
    "\n",
    "ax.scatter(y_test, predicted_test, c=orange, label='Testing')\n",
    "ax.scatter(y_train, predicted_train, c=blue, label='Training')\n",
    "\n",
    "ax.set_xlabel('Reference', fontsize=18)\n",
    "ax.set_ylabel('Prediction', fontsize=18)\n",
    "\n",
    "ax.legend(loc='best', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
