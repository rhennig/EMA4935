{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefb4d72-7d06-4b58-82fd-997ded60fb6c",
   "metadata": {},
   "source": [
    "# Data structures\n",
    "\n",
    "(Based https://www.w3schools.com/python/pandas/ and https://realpython.com/python-data-cleaning-numpy-pandas/)\n",
    "\n",
    "This notebook introduces the Panda Dataframes library. We will learn how to easily load and manipulate data, from selecting or replacing columns and indices to reshaping the data. In short, [Pandas](https://pandas.pydata.org/docs/index.html) uses data such as .csv, .tsv files or a structured query language (SQL) database and turns them into a Python object with rows and columns known as a dataframe. We can think of these objects as analogous to tables available in statistical software like Excel. Just alike Excel, pandas dataframes allow to store and manipulate tabular data in rows of `observations` and columns of `variables`, as well as to extract valuable information from the given data set.\n",
    "\n",
    "A dataframe can be created from scratch, or you can use other data structures, like NumPy arrays. Here are the main types of inputs accepted by a dataframe:\n",
    "\n",
    "* Dict of 1D ndarrays, lists, dicts or series\n",
    "* 2D `numpy.ndarray`\n",
    "* Structured or record ndarray\n",
    "* A series\n",
    "* Another dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a75ec8b-8715-4852-8bc0-28f1a5e37cf9",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f1343-704c-41e2-961f-a3b2da28ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy  as np\n",
    "import pandas  as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Request zip file from url\n",
    "from io             import BytesIO\n",
    "from zipfile        import ZipFile\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296877ae",
   "metadata": {},
   "source": [
    "## 1. Python dictionary\n",
    "\n",
    "To better understand the nature of a dataframe, first let's consider another composite data type in Python called `dictionary`. It is similar to a list but collects objects instead. Just like lists, dictionaries are mutable and dynamic, this means that the can grow or shrink in size as needed and the elements contained therein can be changed. Dictionaries also can be nested with another dictionary or list. However, the main difference is that elements in a dictionary are accessed via `keys`, whereas elements in a list are accessed via indexing.\n",
    "\n",
    "### 1.1 Defining dictionaries\n",
    "\n",
    "We define dictionaries by enclosing a comma-separated list of key:value pairs in braces, where a colon separates each key from its associated value\n",
    "\n",
    "~~~\n",
    "my_dictionary = {\n",
    "    <key> : <value>,\n",
    "    <key> : <value>,\n",
    "    <key> : <value>,\n",
    "          :\n",
    "          :\n",
    "    <key> : <value>\n",
    "}\n",
    "~~~\n",
    "\n",
    "Alternatively, we can use the built-in functin `dict`, where the argument is a list of key,value tuples in the format\n",
    "\n",
    "~~~\n",
    "my_dictionary = dict([\n",
    "    (<key> , <value>),\n",
    "    (<key> , <value>),\n",
    "    (<key> , <value>),\n",
    "           :\n",
    "           :\n",
    "    (<key> , <value>)\n",
    "])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f916709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary using braces\n",
    "atomic_mass = {\n",
    "    \"H\" : 1.00794,\n",
    "    \"He\": 4.002602,\n",
    "    \"Li\": 6.941,\n",
    "    \"Be\": 9.012182,\n",
    "    \"B\" : 10.811,\n",
    "    \"C\" : 12.0107,\n",
    "    \"N\" : 14.0067,\n",
    "    \"O\" : 15.9994,\n",
    "    \"F\" : 18.9984032,\n",
    "    \"Ne\": 20.1797\n",
    "}\n",
    "\n",
    "# Define a dictionary usinf the built-in dict function\n",
    "pauling_electronegativity = dict([\n",
    "    (\"H\" , 2.20),\n",
    "    (\"He\", None),\n",
    "    (\"Li\", 0.98),\n",
    "    (\"Be\", 1.57),\n",
    "    (\"B\" , 2.04),\n",
    "    (\"C\" , 2.55),\n",
    "    (\"N\" , 3.04),\n",
    "    (\"O\" , 3.44),\n",
    "    (\"F\" , 3.98),\n",
    "    (\"Ne\", None)\n",
    "])\n",
    "\n",
    "# Define a dictionary of lists\n",
    "atomic_structure = {\n",
    "    \"H\" : [\"1s1\"],\n",
    "    \"He\": [\"1s2\"],\n",
    "    \"Li\": [\"1s2\", \"2s1\"],\n",
    "    \"Be\": [\"1s2\", \"2s2\"],\n",
    "    \"B\" : [\"1s2\", \"2s2\", \"2p1\"],\n",
    "    \"C\" : [\"1s2\", \"2s2\", \"2p2\"],\n",
    "    \"N\" : [\"1s2\", \"2s2\", \"2p3\"],\n",
    "    \"O\" : [\"1s2\", \"2s2\", \"2p4\"],\n",
    "    \"F\" : [\"1s2\", \"2s2\", \"2p5\"],\n",
    "    \"Ne\": [\"1s2\", \"2s2\", \"2p6\"]\n",
    "}\n",
    "\n",
    "# Define a simple dictionary containing strings\n",
    "strings_dict =dict(\n",
    "    a = \"alpha\",\n",
    "    b = \"beta\",\n",
    "    g = \"gamma\",\n",
    "    d = \"delta\",\n",
    "    e = \"epsilon\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access elements in the dictionary\n",
    "atomic_mass[\"O\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabba4e2",
   "metadata": {},
   "source": [
    "### 1.2 Nested dictionaries\n",
    "\n",
    "As already stated, dictionaries can contain as many dictionaries as needed. This is called nesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e950f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of dictionaries\n",
    "atomic_properties = {\n",
    "    \"mass\"              : atomic_mass,\n",
    "    \"electronegativity\" : pauling_electronegativity,\n",
    "    \"structure\"         : atomic_structure\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c42891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access mass for an element in the dictionary\n",
    "element = \"O\"\n",
    "\n",
    "print(f\"atomic mass for {element} = {atomic_properties['mass'][element]}\\n\" )\n",
    "\n",
    "for idx, shell in enumerate( atomic_properties['structure'][element] ):\n",
    "    print(f\"shell {idx+1} for {element} = \"\n",
    "          f\"{atomic_properties['structure'][element][idx]}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f66097",
   "metadata": {},
   "source": [
    "### 1.3 Assign default values for missing items\n",
    "\n",
    "In order to prevent a runtime error while trying to access data from inexistent keys in a dictionary, we can use the attribute `get` and assign a default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d93fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "element = \"O\"\n",
    "\n",
    "# Access the value for a key in a simple dictionary\n",
    "print(f\"atomic mass for {element} = \"\n",
    "      f\"{atomic_mass.get(element, 'not found')}\")\n",
    "\n",
    "# Access the value for a key in a nested dictionary\n",
    "print(f\"atomic mass for {element} = \"\n",
    "      f\"{atomic_properties.get('mass').get(element, 'not found')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06302d63-6dca-4d1e-8e1d-6e0845bd8bb7",
   "metadata": {},
   "source": [
    "## 2. Pandas Data Structures\n",
    "\n",
    "Pandas provides two types of data structures: **Series** and **DataFrames**:\n",
    "\n",
    "- A **Series** is a one dimensional data structure (“a one dimensional ndarray”) that can store values — and for every value it holds a unique index.\n",
    "\n",
    "- A **DataFrame** is a two (or more) dimensional data structure – basically a table with rows and columns. The columns have names and the rows have indexes.\n",
    "\n",
    "<img src=\"https://github.com/rhennig/EMA6938/blob/main/Notebooks/Figures/Pandas.png?raw=1\" alt=\"Confusion Matrix\" align=\"center\" style=\"width:500px; float:center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339b7c10-b64c-4784-a935-a13ddf602a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame\n",
    "\n",
    "# Using a dict of ndarray/lists\n",
    "data = {\n",
    "  'Element':  ['Titanium', 'Vanadium', 'Manganese',\n",
    "               'Chromium', 'Iron', 'Cobalt', 'Nickel'],\n",
    "  'Z':        [22, 23, 24,\n",
    "                25, 26, 27, 28],\n",
    "  'Magnetism':['Paramagnetic', 'Paramagnetic', 'Complex',\n",
    "               'Antiferromagnetic', 'Ferromagnetic', 'Ferromagnetic', 'Ferromagnetic']\n",
    "}\n",
    "\n",
    "# Load data into a DataFrame object:\n",
    "dataframe = pd.DataFrame(data)\n",
    "\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e0346-cf05-4173-810d-3561aaa49c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, create Pandas DataFrame from lists of lists\n",
    "data = [['Titanium',  22, 'Paramagnetic'],\n",
    "        ['Vanadium',  23, 'Paramagnetic'],\n",
    "        ['Manganese', 24, 'Complex'],\n",
    "        ['Chromium',  25, 'Antiferromagnetic'],\n",
    "        ['Iron',      26, 'Ferromagnetic'],\n",
    "        ['Cobalt',    27, 'Ferromagnetic'],\n",
    "        ['Nickel',    28, 'Ferromagnetic']]\n",
    "\n",
    "# Load data into a DataFrame object:\n",
    "dataframe = pd.DataFrame(data, columns = ['Element', 'Z', 'Magnetism'])\n",
    "\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04ae155-8b98-455e-8d86-ea5cfce1eddf",
   "metadata": {},
   "source": [
    "### Locate Row\n",
    "\n",
    "As you can see from the result above, the DataFrame is like a table with rows and columns.\n",
    "\n",
    "Pandas use the loc attribute to return one or more specified row(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d44368-85f2-4060-b0a0-301fe79f9064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access all datta for a row\n",
    "print( dataframe.loc[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc46ae-dd9d-4515-963e-1c401f5e298f",
   "metadata": {},
   "source": [
    "Note that this example returns a Pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243fa634-f188-4be1-8cb9-6ac38cd8d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access data for multiple entries\n",
    "dataframe.loc[ [0,2,4] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5075ccca-d6c2-42b7-a337-a355277758a8",
   "metadata": {},
   "source": [
    "When using [], the result is a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfdf7e7-afc0-4ed0-ab49-3d6ff3b8271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access data for a given column\n",
    "dataframe.loc[:, 'Magnetism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b054d0-8881-4d65-b42d-8541815ec5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional that returns a boolean Series\n",
    "dataframe[ dataframe['Magnetism'] == 'Ferromagnetic' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aeaa0d",
   "metadata": {},
   "source": [
    "> ## Assignment\n",
    "> Filter the dataframe to return only Ferromagnetic and Paramagnetic elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb795539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e4fed4b-6322-4781-a599-c4beca4c991f",
   "metadata": {},
   "source": [
    "### Named Indices\n",
    "\n",
    "With the index argument, you can name your own indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd37303-7ffa-4f27-ad87-e71fbc3fd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give each row a name\n",
    "dataframe = pd.DataFrame( data, index=['Ti','V','Mn','Cr','Fe','Co','Ni'] )\n",
    "\n",
    "print('DataFrame:\\n', dataframe)\n",
    "\n",
    "# Refer to the named index:\n",
    "print(f\"\\nRefer to names index:\"\n",
    "      f\"\\n{dataframe.loc['Mn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5658f74-5b9c-43a9-ac2b-6ef97e582b62",
   "metadata": {},
   "source": [
    "## 2. Working with CSV Files\n",
    "\n",
    "A simple and widely used method to store big data sets is to use .csv (comma separated-values) files. These files contain plain text and can be read by most software packages, including Pandas.\n",
    "\n",
    "In our examples we will be using a .csv file called cleavage_data.csv. This file contains the energy the cleave a number of materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fc2c2-e6ac-438c-b6e3-65be1ae8cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a file directly from a .zip file on MaterialsCloud.org\n",
    "url = urlopen(\"https://archive.materialscloud.org/record/file?filename=theoreticalCleavedSubstrates.zip&record_id=948\")\n",
    "\n",
    "# Download a .zip file and create pandas DataFrame\n",
    "zipfile   = ZipFile(BytesIO( url.read() ))\n",
    "\n",
    "dataframe = pd.read_csv( zipfile.open('database/cleavage_data.csv') )\n",
    "\n",
    "# Save dataframe to a .csv file\n",
    "#dataframe.to_csv('cleavage_data.csv', index=False)\n",
    "\n",
    "# Information about the data\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e00dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First five data entries\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a4d4da-b599-4d63-b149-134496bfe468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last five data entries\n",
    "dataframe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f6139b-2cb7-4d9a-b4cf-0e473beb2cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print information about the data\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b07d83-a0f2-499f-8081-ee55cb00f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the data\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83743deb-bbdb-443f-8389-e936a464db67",
   "metadata": {},
   "source": [
    "The result tells us there are 4614 rows and 8 columns and the name of each column, with the data type.\n",
    "\n",
    "We also see how many null entries (no values) each column contains. This dataset contains no empty entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8ff673-56bc-4fdb-b73f-f3f2f3764d9c",
   "metadata": {},
   "source": [
    "### 2.1 Cleaning Data\n",
    "\n",
    "Data scientists spend a large amount of their time cleaning datasets. Often these initial steps of obtaining and cleaning data constitute about 80% of the work in a machine learning project.\n",
    "\n",
    "Therefore, we need to learn to deal with messy data, whether that means missing values, inconsistent formatting, malformed records, or nonsensical outliers.\n",
    "\n",
    "Here, we will use the Pandas and NumPy libraries to clean data.\n",
    "\n",
    "We’ll cover the following:\n",
    "- Dropping unnecessary columns in a DataFrame\n",
    "- Changing the index of a DataFrame\n",
    "\n",
    "#### 2.1.1 Dropping Columns in a DataFrame\n",
    "\n",
    "Often, not all the categories of data in a dataset are useful for our analysis. For example, a dataset may contain materials information (composition, crystal structure, thermodynamics data, mechanical, electronic, and magnetic properties) but we may want to focus on analyzing the bulk modulus.\n",
    "\n",
    "In this case, the electronic, and magnetic properties are not important. Retaining these unneeded categories will take up unnecessary space and potentially also bog down runtime.\n",
    "\n",
    "Pandas provides a handy way of removing unwanted columns or rows from a DataFrame with the drop() function. Let’s look at a simple example where we drop a number of columns from a DataFrame.\n",
    "\n",
    "First, let’s use the DataFrame from the CSV file ‘cleavage_data.csv’. In the examples below, we pass a relative path to pd.read_csv, meaning that all of the datasets are in a folder named Datasets in our current working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7e5e9-2984-421c-9917-f3da6cbc2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First five data entries\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12381d3c-65af-41fd-9487-167d87441c78",
   "metadata": {},
   "source": [
    "When we look at the first five entries using the head() method, we can see that a handful of columns provide ancillary information that may not be of interest if we want to select a substrate materials for a synthesis experiment: `Initial formation energy`, `Final formation energy`, `Initial area`.\n",
    "\n",
    "We can drop these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f393f0-5116-4c85-bc92-582fa02ff437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of column names to drop.\n",
    "columns_to_drop = ['Initial formation energy', 'Final formation energy', 'Initial area']\n",
    "\n",
    "# Tell pandas to drop these columns directly in the dataset (inplace = True)\n",
    "dataframe.drop(columns=columns_to_drop, inplace=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cebb01-cd4e-4502-b38f-f014e1cdd2a1",
   "metadata": {},
   "source": [
    "Alternatively, if we know which columns we need, we could pass the names of the columns as a list to the `usecols` argument of `pd.read_csv`.\n",
    "\n",
    "#### 2.1.2 Changing the Index of a DataFrame\n",
    "\n",
    "A Pandas Index extends the functionality of NumPy arrays to allow for more versatile slicing and labeling. In many cases, it is helpful to use a uniquely valued identifying field of the data as its index.\n",
    "\n",
    "For example, in the cleavage dataset, we may want to use the `Substrate Index` as a unique identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff58951-5e6c-4385-af2c-6a42be178d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the Substrate Index is a unique identifier\n",
    "dataframe['Substrate Index'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91112305-c9a3-4929-879c-931c73c2fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s replace the existing index with this column using set_index\n",
    "dataframe.set_index('Substrate Index', inplace=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3038024e-e43e-4705-a648-b375cb75feb9",
   "metadata": {},
   "source": [
    "There are many other ways that Pandas can help us clean data, such as:\n",
    "- Dealing with empty cells\n",
    "- Using .str() methods to clean columns\n",
    "- Using the DataFrame.applymap() function to clean the entire dataset, element-wise\n",
    "- Renaming columns to a more recognizable set of labels\n",
    "- Skipping unnecessary rows in a .csv file\n",
    "- Remove duplicate entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7408ba",
   "metadata": {},
   "source": [
    "#### 2.1.3 Dealing with outliers\n",
    "\n",
    "In machine learning, the training data determines the accuracy and effectiveness of models. However, the presence of outliers can impact the performance of the model. These can arise due to various factors such as measurement errors, data corruption, or anomalies in the data. We need to identify data points that deviate significantly from the normal distribution of a dataset as they can distort statistical analysis and lead to inaccurate predictions. Detecting and addressing data outliers is the first step to ensuring a high-quality dataset.\n",
    "\n",
    "Using a dataframe simplifies the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34bdfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean    = dataframe['Surface Energy'].mean()\n",
    "std_dev = dataframe['Surface Energy'].std()\n",
    "\n",
    "lower_bound = mean - 3.0 * std_dev\n",
    "upper_bound = mean + 3.0 * std_dev\n",
    "\n",
    "print(f\"listing outliers for {lower_bound:.3f} < Surface Energy < {upper_bound:.3f}\\n\")\n",
    "\n",
    "dataframe[ (dataframe['Surface Energy'] < lower_bound) | (dataframe['Surface Energy'] > upper_bound) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c9111-28c7-4db2-8e16-af0fc32c9011",
   "metadata": {},
   "source": [
    "## 3. Use Seaborn and Pandas to plot the data\n",
    "\n",
    "[Seaborn](https://seaborn.pydata.org) is a library for making statistical graphics in Python. It builds on top of matplotlib and integrates closely with Pandas data structures. The plotting functions on Seaborn operate on dataframes and arrays containing whole datasets and internally perform the necessary semantic mapping and statistical aggregation to produce informative plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4037f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate and univariate graph for two properties in the dataframe\n",
    "\n",
    "sns.jointplot(data=dataframe, x=\"Initial formation energy\", y=\"Final formation energy\",\n",
    "              xlim=(-0.5,2.5), ylim=(-0.5,2.5), kind=\"kde\", cmap=\"viridis\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f8749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a distribution for the work of cleavage\n",
    "\n",
    "sns.histplot(dataframe[\"Work of Cleavage\"], bins=100, line_kws={\"linewidth\":3}, kde=False)\n",
    "\n",
    "plt.xlabel(\"Work of cleavage\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.xlim(-0.5,3.5)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
