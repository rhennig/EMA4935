{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73c9ac1-6918-43ff-ada6-4b0753d7811a",
   "metadata": {},
   "source": [
    "# Materials Project Database\n",
    "\n",
    "This notebook also illustrates how we can interface with the [Materials Project](https://materialsproject.org) (MP) database. We will use the MP data retrieval tool and convert it to a pandas dataframe, then apply matminer's tools to populate the dataframe with descriptors/features from pymatgen, and finally fit a linear regression model from the scikit-learn library to the dataset.\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Load and examine a dataset in a pandas dataframe\n",
    "2. Add descriptors to the dataframe using matminer\n",
    "3. Train and visualize a linear regression machine learning methods with scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aafed2c-5ef3-432b-be23-27a4d90e4759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install mp_api\n",
    "#%pip install matminer\n",
    "#%pip install flatten_dict # Patch Materials Project API downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f39e03",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c133f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy                          as np\n",
    "import pandas                         as pd\n",
    "import seaborn                        as sns\n",
    "\n",
    "import matplotlib.pyplot              as plt\n",
    "\n",
    "from scipy                            import stats\n",
    "from flatten_dict                     import flatten\n",
    "from mp_api.client                    import MPRester\n",
    "\n",
    "from pymatgen.core                    import Composition\n",
    "from matminer.utils.data              import PymatgenData\n",
    "from matminer.featurizers.composition import ElementProperty\n",
    "\n",
    "from sklearn.metrics                  import mean_squared_error\n",
    "from sklearn.linear_model             import LinearRegression\n",
    "from sklearn.model_selection          import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ff5f9-136f-4dea-ad1e-db73df60145b",
   "metadata": {},
   "source": [
    "## 1. Load and process data set\n",
    "\n",
    "We use MPRester to load a data set of materials properties from MaterialsProject. To download data from [Materials Project](https://materialsproject.org), you will need to create an account. Simply go the page, and \"Sign in or Register.\" Then select \"API\" in the upper left of the screen and copy your API key.\n",
    "\n",
    "You can either set the environment variable MAPI_KEY to your API key or simply add the API key in Python. To set the environment variable MAPI_KEY in Miniconda/Anaconda:\n",
    "\n",
    "`conda env config vars set MAPI_KEY=\"api_key_from_materialsproject\"`\n",
    "\n",
    "To activate the environment variable, you need to restart Miniconda/Anaconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MPRester to get data from MaterialsProject. Set to None if using the environment variable.\n",
    "api_key = None\n",
    "\n",
    "# Create an adapter to the MP Database.\n",
    "mpr = MPRester(api_key) \n",
    "\n",
    "# Get list with fields available for extraction\n",
    "mpr.materials.summary.available_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6975fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for materials with the selected properties\n",
    "properties = ['formula_pretty', 'bulk_modulus'\n",
    "              'formation_energy_per_atom','band_gap',\n",
    "              'energy_above_hull','density',\n",
    "              'volume', 'nsites']\n",
    "\n",
    "docs = mpr.materials.summary.search(fields=properties)\n",
    "\n",
    "# Patch Materials Project API downloads\n",
    "flattened = [{\n",
    "      k: v\n",
    "      for k, v in flatten(doc.model_dump(), reducer=\"dot\").items()\n",
    "      if k != \"fields_not_requested\"\n",
    "  } for doc in docs]\n",
    "\n",
    "# Create a dataframe with the selected properties\n",
    "dataframe = pd.DataFrame.from_records(flattened)\n",
    "\n",
    "dataframe = dataframe.drop(columns=[col for col in dataframe if col not in properties])\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f16b8d",
   "metadata": {},
   "source": [
    "Quick inspection of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1a8574",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522d6326-d5a6-434a-beb2-424a9976f93e",
   "metadata": {},
   "source": [
    "### 1.1 Filter unstable materials\n",
    "\n",
    "The data set above has some entries that correspond to thermodynamically or mechanically unstable materials. We filter these materials out using the distance from the convex hull and `K_VRH` (the Voight-Reuss-Hill average of the bulk modulus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da476d-8552-4ec4-8f2e-48ede3295d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter materials that are unstable by 100 meV/atom or more\n",
    "# against decomposition into other phases\n",
    "dataframe = dataframe[ dataframe['energy_above_hull'] < 0.1 ]\n",
    "\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4019e5-9acf-4847-8b79-080a8b8fe351",
   "metadata": {},
   "source": [
    "### 1.2 Create a New Descriptor\n",
    "\n",
    "We can create a new desciptor, e.g, the volume per atom, and add it to the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7126e8b-b743-443f-ad94-fdba6527e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to the pandas dataframe for the volume per atom as a new descriptor\n",
    "dataframe['volume_per_atom'] = dataframe['volume']/dataframe['nsites']\n",
    "\n",
    "# Verify the added column\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda34ee-26c5-4e49-8ec9-b08317e81ca4",
   "metadata": {},
   "source": [
    "### 1.3 Add More Descriptors\n",
    "\n",
    "We use MatMinerâ€™s pymatgen descriptor tools to add some more descriptors to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f4a4f-4a61-452f-abfd-b7c6db6c3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"composition\"] = dataframe['formula_pretty'].map(lambda x: Composition(x))\n",
    "\n",
    "dataset     = PymatgenData()\n",
    "\n",
    "descriptors = ['row', 'group', 'atomic_mass',\n",
    "               'atomic_radius', 'boiling_point', 'melting_point', 'X']\n",
    "\n",
    "statisctics = [\"mean\", \"std_dev\"]\n",
    "\n",
    "element_property = ElementProperty(data_source=dataset, features=descriptors, stats=statisctics)\n",
    "\n",
    "dataframe        = element_property.featurize_dataframe(dataframe, \"composition\")\n",
    "\n",
    "# Remove NaN values\n",
    "dataframe = dataframe.dropna()\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f4881-8bbd-40d7-9ccb-96af3673778f",
   "metadata": {},
   "source": [
    "## 2. Fit a Linear Regression Model Using SciKitLearn\n",
    "\n",
    "We now have a sufficiently detailed dataset to fit a linear regression model that predicts the density. The linear model is given by\n",
    "$$\n",
    "y(x) = \\beta_0 + \\sum_{i=1}^n \\beta_i\\, x_i,\n",
    "$$\n",
    "where $x_i$ denotes the $n$ descriptors.\n",
    "\n",
    "But before we proceed to the fitting, we need to remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3669e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean    = dataframe['density'].mean()\n",
    "std_dev = dataframe['density'].std()\n",
    "\n",
    "lower_bound = mean - 3.0 * std_dev\n",
    "upper_bound = mean + 3.0 * std_dev\n",
    "\n",
    "print(f\"removing outliers for {lower_bound:.3f} < density < {upper_bound:.3f}\\n\")\n",
    "\n",
    "dataframe = dataframe[ (dataframe['density'] > lower_bound) & (dataframe['density'] < upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaa4ce5",
   "metadata": {},
   "source": [
    "### 2.1 Define the target output and relevant descriptors\n",
    "\n",
    "The data set above has many columns - we won't need all this data for our modeling. We try to predict density. We can drop most of the other output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c581347e-a73b-4561-90e1-e58f761e8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target output column\n",
    "y = dataframe['density'].values\n",
    "\n",
    "# Possible descriptor columns\n",
    "excluded = [\"band_gap\", \"formula_pretty\", \"density\",\n",
    "            \"volume\", \"nsites\", \"volume_per_atom\",\n",
    "            \"energy_above_hull\", \"composition\"]\n",
    "\n",
    "# Remove descriptors from dataframe\n",
    "X = dataframe.drop(excluded, axis=1)\n",
    "\n",
    "descriptor_values = '\\n'.join(X.columns.values)\n",
    "print(f\"There are {X.shape[1]} possible descriptors:\\n\\n{descriptor_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d9f021-f20a-4151-817f-e6e60b19431a",
   "metadata": {},
   "source": [
    "### 2.2 Fit the linear regression model\n",
    "\n",
    "Now that we have our set of descriptors, we use scikit learn to do a linear fit to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db557258-ec32-45f2-9d8d-dbb3d0381e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define linear regression object\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "# Fit linear regression to the data\n",
    "linear_regression.fit(X, y)\n",
    "\n",
    "mse = mean_squared_error( y_true=y, y_pred=linear_regression.predict(X) )\n",
    "\n",
    "# Get fit statistics\n",
    "print(f\"Training R2   = {linear_regression.score(X, y):.4f}\")\n",
    "print(f\"Training RMSE = {np.sqrt(mse):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f263e9-c8b6-4195-b165-4f57732bc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a 10-fold cross validation (90% training, 10% test)\n",
    "crossvalidation = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Compute cross validation scores the model\n",
    "r2_scores   = cross_val_score(linear_regression, X, y,\n",
    "                              scoring='r2', cv=crossvalidation, n_jobs=1)\n",
    "\n",
    "mse_scores  = cross_val_score(linear_regression, X, y,\n",
    "                              scoring='neg_mean_squared_error', cv=crossvalidation, n_jobs=1)\n",
    "\n",
    "rmse_scores = [np.sqrt(abs(s)) for s in mse_scores]\n",
    "\n",
    "\n",
    "print(\"\\n\".join(f\"fold {idx+1:2}, R2 = {i:.4f}\" for idx, i in enumerate(r2_scores)))\n",
    "\n",
    "print(f\"\\nCross-validation results:\\n\"\n",
    "      \n",
    "      f\"Folds: {len(r2_scores)}, mean R2   = \"\n",
    "      f\"{np.mean(np.abs(r2_scores)):.3f}\\n\"\n",
    "\n",
    "      f\"Folds: {len(rmse_scores)}, mean RMSE = \"\n",
    "      f\"{np.mean(np.abs(rmse_scores)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b83b795",
   "metadata": {},
   "source": [
    "Finally, we can visualize the results using a scatter plot with kernel density estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_predicted = np.stack([ y, linear_regression.predict(X)], axis=1)\n",
    "\n",
    "results_frame = pd.DataFrame( reference_predicted,\n",
    "                             columns=[\"reference\", \"predicted\"] )\n",
    "\n",
    "reference_predicted = reference_predicted.reshape( (2,-1) )\n",
    "\n",
    "kernel  = stats.gaussian_kde(reference_predicted)(reference_predicted)\n",
    "idx     = kernel.argsort()\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(6,6) )\n",
    "\n",
    "ax.plot([-20, 20], [-20, 20], color=\"black\",\n",
    "        label=None, ls=\"solid\", lw=1, zorder=0)\n",
    "\n",
    "pcm = sns.scatterplot(ax=ax, data=results_frame,\n",
    "                      x=results_frame[\"predicted\"][idx],\n",
    "                      y=results_frame[\"reference\"][idx],\n",
    "                      c=kernel[idx], s=4**2,\n",
    "                      edgecolor=\"none\")\n",
    "\n",
    "mappable = plt.cm.ScalarMappable()\n",
    "\n",
    "cbar = fig.colorbar(mappable=mappable, ax=ax,\n",
    "                    location=\"right\", orientation=\"vertical\",\n",
    "                    shrink=0.70, pad=0.01)\n",
    "\n",
    "cbar.ax.set_title(f\"Density\", x=0.6, y=1.02, rotation=90)\n",
    "\n",
    "ax.set_xlim(0, 17.5)\n",
    "ax.set_ylim(0, 17.5)\n",
    "\n",
    "ax.set_xlabel(r\"Predicted [g cm$^{-3}$]\")\n",
    "ax.set_ylabel(r\"Reference [g cm$^{-3}$]\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
