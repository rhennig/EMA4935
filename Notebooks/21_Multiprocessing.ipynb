{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0130ee-32ea-40a6-8e2c-210a6c0f17ce",
   "metadata": {},
   "source": [
    "# Parallel programming in Python\n",
    "\n",
    "Several applications in science, research, and others, rely on performing iterable tasks than can increase in size and complexity rather rapidly. Most often, these can become a bottleneck for fast computation of results. In traditional serial computing, a single task is executed at a time. When tasks are executed sequentially, the program waits for each task to complete before moving on to the next. This can lead to waisting processing time, especially if some tasks are independent and don't need to wait for others to complete. However, with parallel processing, multiple tasks are executed simultaneously, resulting in faster execution times. In this case, tasks are divided and allocated to different processors. Each processor works on its assigned task simultaneously, thereby reducing the overall execution time. This is particularly beneficial in programs where tasks are independent.\n",
    "\n",
    "## Overview\n",
    "\n",
    "When interested in doing high-throughput computing, we can benefit from running multiple tasks concurrently. In this notebook we will learn the basic implementations for running parallel computations in python. We focus attention of two alternatives, namely, the [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) and [dask](https://docs.dask.org/en/stable/delayed.html) libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d786eb-029b-4be9-bf78-1a76aec9f786",
   "metadata": {},
   "source": [
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af948e-a07d-4208-992a-d3e01b6ff2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import dask\n",
    "import math\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "global cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4783e235-ee51-4d54-a773-78ecf9c94676",
   "metadata": {},
   "source": [
    "# 2. Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b667cb5-7d69-40a8-8dfc-60938a52e607",
   "metadata": {},
   "source": [
    "We start by defining two functions. The first, `driver`, consists of doing a simple operation on a given number and returning that result. Notice, however, that you can include your choice of implementation within this callable function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cefdf6-7a43-4021-87a0-dad600c4d2a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def driver(number, num=0.0, den=0.0):\n",
    "    \n",
    "    numerator   = math.log(number + num + 1.0)\n",
    "    denominator = math.sqrt(number + den + 1.0)\n",
    "    \n",
    "    result      = numerator/denominator\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee8e53-6af2-4988-a9f5-1e5c6aef5131",
   "metadata": {},
   "source": [
    "The second, `collect`, will call the garbage collector to help us clean up after running our tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6efad-728f-434f-9a40-6bae417e565d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collect():\n",
    "    \n",
    "    gc.collect(2)\n",
    "    gc.collect(1)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a09d4ea-0f1e-4e66-9b25-a550b90ac718",
   "metadata": {},
   "source": [
    "A third function called `array` will help us generate a list with variable and optional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978e250-e6af-4bba-af4a-a079d5281a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def array(size, num=0.0, den=0.0, option='none'):\n",
    "    \n",
    "    arguments = ( (i, num, den) for i in range(size) ) if 'star' in option.lower() else ( i for i in range(size) )\n",
    "    \n",
    "    return arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8e4bc7-1b8f-4a6a-bd8a-f8ee08b0beb4",
   "metadata": {},
   "source": [
    "We are all set. Now let's have a look at the available cores. For that we can use the `mp.cpu_count()` function. Please keep in mind that one should not assign all available cores for our computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e043d-a4be-4a00-86a1-9495437f2452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'{mp.cpu_count() = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68614175-b608-43c6-acfb-9f91f9a28986",
   "metadata": {},
   "source": [
    "Once we know our resources, we can select an appropriate number of cores for running parallel computations. We will assign the number to the global variable `cores`. It will be available for all the functions in our Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab02bd-4216-4ecb-9497-57ecdaddbeca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cores = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ab7d34-b544-45b0-8853-09700fc84ed9",
   "metadata": {},
   "source": [
    "Now we need to define a base line in order to compare our different implementations. This will be the `serial` run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8d4c1-e4d7-46fd-a740-dea4bd8ecb60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def serial(args, num=0.0, den=0.0):\n",
    "    \n",
    "    result = [ driver(i, num, den) for i in args]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3f3b34-6101-4d9e-8146-3209529d79fe",
   "metadata": {},
   "source": [
    "## 2.1 `map`, `map_async`, `starmap` and `starmap_async`\n",
    "\n",
    "The multiprocessing library provides with a class called `Pool`. As its name suggests, it creates a pool of worker processes. The Pool object creates by default a worker process per core. There are three methods available for the Pool object, these are map, map_async, starmap, and starmap_async. The difference between the synchornous and asynchronous methods is that the later provide a workaround to the limitations related to blocking processes. These methods do not block the pool until tasks are complete, instead, they return an `AsyncResult` object from which the results may be retrieved.\n",
    "\n",
    "* The `map` function usually is applied to each item in an iterable variable. It then submits all items as tasks to the pool then blocks it until all tasks are complete. This method is limited to functions that make use of a single argument.\n",
    "\n",
    "* The `starmap` function extends the `map` functionality to callable functions requiring more that a single argument.\n",
    "\n",
    "* The `map_async` function corresponds to the asynchronous version of `map`.\n",
    "\n",
    "* The `starmap_async` function provides an asynchronous version of `starmap`.\n",
    "\n",
    "Creating a pool consits of three basic steps:\n",
    "\n",
    "1. Define the Pool object\n",
    "2. Execute the Pool\n",
    "3. Terminate the Pool.\n",
    "\n",
    "Let's write the code for these steps for the `driver` we defined previously. **NOTE** In order to avoid conflicts between processes, it is good practice to create the Pool object within some function() or main()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b14fe-e760-4824-8618-3e65d9cc5e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "#\n",
    "### Step 1. Define the pool\n",
    "#\n",
    "    pool = mp.Pool(cores)\n",
    "#\n",
    "### Run the Pool\n",
    "#\n",
    "    result_parallel = pool.map(driver, (i for i in range(64)))\n",
    "#\n",
    "### Terminate the Pool\n",
    "#\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947c5278-5274-4e38-bbaa-09409397da9b",
   "metadata": {},
   "source": [
    "The `serial` run, instead, looks like the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd33dd-d14f-443a-b9a9-733fcd4f0e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_serial = [ driver(i) for i in range(64) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c41f5ed-7dea-4f88-a450-8f22f5d7f66f",
   "metadata": {},
   "source": [
    "Verify that both approaches yield the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd024c-c58d-43f7-a5a7-bb377642173a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(result_serial)\n",
    "print(result_parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60124a34-5a51-488e-9c8e-93d6e91d4299",
   "metadata": {},
   "source": [
    "For practical purposes and ease of implementation, we can wrap all three methods in a single function called `parallel`. Let's write it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25924560-6031-48ff-8d7d-7b018a8b7a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b022ac1-5db3-4992-8889-236e7d70c0b8",
   "metadata": {},
   "source": [
    "Run some quick tests to compare the execution time for different choices of Pool and array size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5180d0-a580-4371-8b9d-b85ce2ec18f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "#\n",
    "### Define parameters\n",
    "#\n",
    "\n",
    "#\n",
    "### Serial run\n",
    "#\n",
    "\n",
    "#\n",
    "### Parallel runs\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394f1d9-fef7-4183-9843-4d48698d4056",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can also use the `with` context manager. This alternative greatly facilitates implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d162a-23a5-4bdb-814f-44f39228c6d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with mp.Pool(cores) as pool:\n",
    "    result = pool.starmap( driver, ( (i, 3.0, 3.0) for i in range(64) ) )\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550273f-f1e3-4fee-aa27-924192f32219",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Dask\n",
    "\n",
    "Dask provides the means for dealing with larger-than-memory data sets, it achieves this through multicore and distributed parallel execution. It is simple to use, first we import a Python Dask dependency named `delayed` that is used to achieve the parallelization, then we wrap the functions or methods to the delayed function. That's it! However, you might notice that running that code results in the lazy object of the delayed function. This instance contains everything that you need to compute the result. To get the result you must call the `compute()` method.\n",
    "\n",
    "Let's have a look at a simple code snipet that illustrates the previous paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b32ab2-08a5-4753-9929-fffe60f72c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    num, den = 0.0, 0.0\n",
    "    \n",
    "    size     = 4**8\n",
    "    \n",
    "    print(f'evaluating array with {size:,} elements')\n",
    "    \n",
    "    for scheduler in ['single-threaded','synchronous', 'threading','multiprocessing', 'processes']:\n",
    "        print(f'\\n{scheduler = }')\n",
    "        \n",
    "        iterator = [ dask.delayed(driver)(i, num=num, den=den) for i in range(size) ]\n",
    "        \n",
    "        %timeit -n 10 -r 2 dask.compute(*iterator, scheduler=scheduler, n_workers=cores)\n",
    "        \n",
    "        collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e0d4c-1bfc-4782-85b7-20fd790cbe90",
   "metadata": {},
   "source": [
    "## 3.1 Cluster and Client\n",
    "\n",
    "Dask also offers the possibility to define a `LocalCluster` that sets the environment for computation. Then, we may start a `Client` for our runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bb247f-f7f8-4972-bb0e-d3e85cd826cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num, den = 0.0, 0.0\n",
    "\n",
    "size     = 4**10\n",
    "\n",
    "with LocalCluster( n_workers=cores) as cluster, Client() as client:\n",
    "\n",
    "    iterator = [ dask.delayed(driver)(i, num=num, den=den) for i in range(size) ]\n",
    "\n",
    "    result   = client.compute(iterator)\n",
    "\n",
    "    %timeit -n 10 -r 2 client.gather(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce19729-7fd8-4978-affb-493eff47a76b",
   "metadata": {},
   "source": [
    "For those cases where we want to interact and modify constantly the settings for our computing environment, it is beneficial to instantiate our cluster and client in interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19ebbf-544b-4ad3-8f2f-d23f442300e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=cores)\n",
    "client  = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07b538f-f155-4bd8-acdf-0689dff33d1f",
   "metadata": {},
   "source": [
    "Now we can interact directly with the cluster and client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b84328-6c5e-4f24-811e-76385a0c4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a82a57-5935-4428-926e-e075a13a0def",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3bf3d-bff1-45fa-8e0f-5a242f78a4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num, den = 0.0, 0.0\n",
    "\n",
    "size     = 1000\n",
    "\n",
    "iterator = [ dask.delayed(driver)(i, num=num, den=den) for i in range(size) ]\n",
    "\n",
    "result   = client.compute(iterator)\n",
    "\n",
    "%timeit -n 10 -r 2 client.gather(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23811241-1b52-4fb1-8a73-482ed565dcb7",
   "metadata": {},
   "source": [
    "Once we are done with our computations, we **MUST CLOSE** the client and cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b68a3-a1ea-40f0-837a-2072701b3d47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
